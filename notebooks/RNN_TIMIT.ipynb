{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN TIMIT demo\n",
    "\n",
    "This notebook is an extension of the previous one on MLP. To find more details, read that one first.\n",
    "\n",
    "*This is still work in progress!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "#os.environ['KERAS_BACKEND']='tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K40c (CNMeM is disabled, cuDNN 5004)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import *\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import sys\n",
    "from tqdm import *\n",
    "\n",
    "sys.path.append('../python')\n",
    "\n",
    "from data import Corpus, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=Corpus('../data/TIMIT_train.hdf5',load_normalized=True, merge_utts=True)\n",
    "dev=Corpus('../data/TIMIT_dev.hdf5',load_normalized=True, merge_utts=True)\n",
    "test=Corpus('../data/TIMIT_test.hdf5',load_normalized=True, merge_utts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777\n"
     ]
    }
   ],
   "source": [
    "maxlen=max([train.getMaxLen(),dev.getMaxLen(),test.getMaxLen()])\n",
    "print maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1124823, 39)\n",
      "(1124823,)\n",
      "60\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-91c5615060b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_out_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mtr_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtr_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mdev_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdev_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "tr_in,tr_out_dec=train.get()\n",
    "dev_in,dev_out_dec=dev.get()\n",
    "tst_in,tst_out_dec=test.get()\n",
    "\n",
    "h5_out = h5py.File('timit.h5', 'w')\n",
    "dset = h5_out.create_dataset('train_x', tr_in.shape, dtype='f')\n",
    "dset[...] = tr_in\n",
    "dset = h5_out.create_dataset('dev_x', dev_in.shape, dtype='f')\n",
    "dset[...] = dev_in\n",
    "dset = h5_out.create_dataset('test_x', tst_in.shape, dtype='f')\n",
    "dset[...] = tst_in\n",
    "dset = h5_out.create_dataset('train_y', tr_out_dec.shape, dtype='i')\n",
    "dset[...] = tr_out_dec\n",
    "dset = h5_out.create_dataset('dev_y', dev_out_dec.shape, dtype='i')\n",
    "dset[...] = dev_out_dec\n",
    "dset = h5_out.create_dataset('test_y', tst_out_dec.shape, dtype='i')\n",
    "dset[...] = tst_out_dec\n",
    "h5_out.close()\n",
    "\n",
    "\n",
    "print(tr_in.shape)\n",
    "print(tr_out_dec.shape)\n",
    "print(np.max(tr_out_dec))\n",
    "for u in range(tr_in.shape[0]):\n",
    "    tr_in[u]=tr_in[u][:,:26]\n",
    "for u in range(dev_in.shape[0]):    \n",
    "    dev_in[u]=dev_in[u][:,:26]\n",
    "for u in range(tst_in.shape[0]):\n",
    "    tst_in[u]=tst_in[u][:,:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim=tr_in[0].shape[1]\n",
    "output_dim=61\n",
    "hidden_num=140\n",
    "epoch_num=50\n",
    "\n",
    "def dec2onehot(dec):\n",
    "    ret=[]\n",
    "    for u in dec:\n",
    "        assert np.all(u<output_dim)\n",
    "        num=u.shape[0]\n",
    "        r=np.zeros((num,output_dim))\n",
    "        r[range(0,num),u]=1\n",
    "        ret.append(r)\n",
    "    return np.array(ret)\n",
    "\n",
    "tr_out=dec2onehot(tr_out_dec)\n",
    "dev_out=dec2onehot(dev_out_dec)\n",
    "tst_out=dec2onehot(tst_out_dec)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pad_feat(data,maxlen):   \n",
    "    \n",
    "    s=data.shape[0]\n",
    "    f=data[0].shape[1]\n",
    "    \n",
    "    ret=np.zeros((s,maxlen,f))\n",
    "    for u in range(s):\n",
    "        w=data[u].shape[0]\n",
    "        ret[u,:w,:]=data[u]\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def get_masking(data,maxlen):\n",
    "    s=data.shape[0]    \n",
    "    ret=np.zeros((s,maxlen))\n",
    "    for u in range(s):\n",
    "        w=data[u].shape[0]\n",
    "        ret[u,:w]=1\n",
    "    return ret\n",
    "\n",
    "tr_in=pad_feat(tr_in,maxlen)\n",
    "dev_in=pad_feat(dev_in,maxlen)\n",
    "tst_in=pad_feat(tst_in,maxlen)\n",
    "\n",
    "tr_out=pad_feat(tr_out,maxlen)\n",
    "dev_out=pad_feat(dev_out,maxlen)\n",
    "tst_out=pad_feat(tst_out,maxlen)\n",
    "\n",
    "#tr_sw=get_masking(tr_out_dec,maxlen)\n",
    "#tst_sw=get_masking(tst_out_dec,maxlen)\n",
    "#dev_sw=get_masking(dev_out_dec,maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "class LSTM_w_peepholes(LSTM):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(LSTM_w_peepholes, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self):\n",
    "        super(LSTM_w_peepholes,self).build()\n",
    "        \n",
    "        self.P_i = self.inner_init((self.output_dim, self.output_dim),\n",
    "                                   name='{}_P_i'.format(self.name))\n",
    "        self.P_f = self.inner_init((self.output_dim, self.output_dim),\n",
    "                                   name='{}_P_f'.format(self.name))\n",
    "        self.P_o = self.inner_init((self.output_dim, self.output_dim),\n",
    "                                   name='{}_P_o'.format(self.name))\n",
    "        \n",
    "        self.trainable_weights.append(self.P_i)\n",
    "        self.trainable_weights.append(self.P_f)\n",
    "        self.trainable_weights.append(self.P_o)\n",
    "\n",
    "        \n",
    "    \n",
    "    def step(self, x, states):\n",
    "        h_tm1 = states[0]\n",
    "        c_tm1 = states[1]\n",
    "        if len(states) == 3:\n",
    "            B_U = states[2]\n",
    "        else:\n",
    "            B_U = [1. for _ in range(4)]\n",
    "\n",
    "        x_i = x[:, :self.output_dim]\n",
    "        x_f = x[:, self.output_dim: 2 * self.output_dim]\n",
    "        x_c = x[:, 2 * self.output_dim: 3 * self.output_dim]\n",
    "        x_o = x[:, 3 * self.output_dim:]\n",
    "\n",
    "        i = self.inner_activation(x_i + K.dot(h_tm1 * B_U[0], self.U_i) + K.dot(c_tm1,self.P_i))\n",
    "        f = self.inner_activation(x_f + K.dot(h_tm1 * B_U[1], self.U_f) + K.dot(c_tm1,self.P_f))\n",
    "        c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1 * B_U[2], self.U_c))\n",
    "        o = self.inner_activation(x_o + K.dot(h_tm1 * B_U[3], self.U_o) + K.dot(c_tm1,self.P_o))\n",
    "\n",
    "        h = o * self.activation(c)\n",
    "        return h, [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(LSTM_w_peepholes(input_dim=input_dim,output_dim=hidden_num,return_sequences=True))\n",
    "model.add(LSTM(input_dim=input_dim,output_dim=hidden_num,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(output_dim=output_dim)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#optimizer = SGD(lr=4e-3, momentum=0.9, nesterov=False)\n",
    "#optimizer= Adam(lr=0.0001)\n",
    "optimizer=RMSprop(lr=4e-3)\n",
    "loss='categorical_crossentropy'\n",
    "metrics=['accuracy']\n",
    "          \n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_hist=History('Train')\n",
    "dev_hist=History('Dev')\n",
    "tst_hist=History('Test')\n",
    "\n",
    "tr_it=range(tr_in.shape[0])\n",
    "\n",
    "for e in range(epoch_num):\n",
    "    \n",
    "    print 'Epoch #{}/{}'.format(e+1,epoch_num)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    shuffle(tr_it)\n",
    "    for u in tqdm(tr_it):\n",
    "        l,a=model.train_on_batch(np.array([tr_in[u]]),np.array([tr_out[u]]))\n",
    "        tr_hist.r.addLA(l,a,tr_out[u].shape[0])        \n",
    "    clear_output()    \n",
    "    tr_hist.log()\n",
    "    \n",
    "    for u in range(dev_in.shape[0]):\n",
    "        l,a=model.test_on_batch(np.array([dev_in[u]]),np.array([dev_out[u]]))\n",
    "        dev_hist.r.addLA(l,a,dev_out[u].shape[0])\n",
    "    dev_hist.log()\n",
    "    \n",
    "    \n",
    "    for u in range(tst_in.shape[0]):\n",
    "        l,a=model.test_on_batch(np.array([tst_in[u]]),np.array([tst_out[u]]))\n",
    "        tst_hist.r.addLA(l,a,tst_out[u].shape[0])\n",
    "    tst_hist.log()            \n",
    "    \n",
    "print 'Done!'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as P\n",
    "%matplotlib notebook\n",
    "\n",
    "fig,ax=P.subplots(2,sharex=True,figsize=(12,10))\n",
    "\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].plot(tr_hist.loss,label='Train')\n",
    "ax[0].plot(dev_hist.loss,label='Dev')\n",
    "ax[0].plot(tst_hist.loss,label='Test')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_title('PER %')\n",
    "ax[1].plot(100*(1-np.array(tr_hist.acc)),label='Train')\n",
    "ax[1].plot(100*(1-np.array(dev_hist.acc)),label='Dev')\n",
    "ax[1].plot(100*(1-np.array(tst_hist.acc)),label='Test')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Min test PER: {:%}'.format(1-np.max(tst_hist.acc))\n",
    "print 'Min dev PER epoch: #{}'.format((np.argmax(dev_hist.acc)+1))\n",
    "print 'Test PER on min dev: {:%}'.format(1-tst_hist.acc[np.argmax(dev_hist.acc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
